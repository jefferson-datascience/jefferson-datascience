<img src="https://github.com/jefferson-datascience/jefferson-datascience/blob/main/logo_estudos.jpg" alt="logo" style="zoom: 100%"/>

## Sobre Mim

Olá! Seja Bem-Vindo ao meu GitHub! 

Meu nome é Jefferson Henrique, sou Mestre e Bacharel em Matemática. No momento atual, tenho dedicação exclusiva ao estudo da Ciências de Dados e, aqui, você vai encontrar meus projetos de Ciências de Dados que eu desenvolvo com o objetivo de aprimorar as minhas habilidades, técnicas e ferramentas de resolver problemas de negócios utilizando análise exploratória de dados, inteligência de dados e negócio, e, Machine Learning. 

Segue abaixo os projetos desenvolvidos e um teaser sobre o que foi desenvolvido.


## Projetos Desenvolvidos


**[Projeto House Rocket Company:](https://github.com/jefferson-datascience/project_insight_house_rocket)** Nesse projeto, para ajudar o CEO da Imobiliária House Rocket a encontrar ótimas oportunidades de negócio, foi desenvolvido uma Análise Exploratória e realizada uma Inteligência de Dados com o objetivo de obter os melhores imóveis para compra e determinar os melhores preços para revenda desses imóveis comprados de acordo com a sazonalidade. 
<p>O custo estimado de Aquisição foi de US$ 4.094.212.008,00, o faturamento das vendas foi estimado em US$ 5.276.791.316,98 e, com isso, o lucro estimado é de US$ 1.182.579.308,98. Além disso, para otimizar o processo de consulta a esses dados, criei um Dashboard com todas informações que está disponível na nuvem para ser consultado bastando apenas ter um dispositivo móvel em mãos e Internet. Segue o link:</p> 

<sub>**Ferramentas e Bibliotecas Utilizadas:** Python, Pandas, Numpy, Seaborn, Jupyter Notebook, Pycharm, Streamlit, Render.</sub>


**[Projeto StarJeans! Store:](https://github.com/jefferson-datascience/project_starjeans_store)** Nesse projeto, com o propósito de ajudar os donos da e-commerce de moda masculina StarJeans!Store a tomarem a decisão de quais preços deviam ser estipulados, quais matérias-primas deviam ser adquiridas e quais os melhores estilos deviam ser produzidos para as calças que desejam vender, foi desenvolvido dois scripts de Webscraping para extrair informações das suas duas principais concorrentes, que são a H&M e a Macy's e, a partir dessas informações, tomarem as melhores decisões. 
<p>Além desses scripts, foi elaborado uma Análise Exploratória e uma Inteligência de Dados dessas informações extraídas com o foco de dar mais apoio na tomada de decisão de negócio. Para otimizar o processo de consulta a esses dados, criei um Dashboard com todas informações que está disponível na nuvem para ser consultado bastando apenas ter um dispositivo móvel em mãos e Internet. Segue o link:</p>  

<sub>**Ferramentas e Bibliotecas Utilizadas:** Python, Pandas, Numpy, Selenium, Beautiful Soup, Streamlit, Render, Seaborn.</sub>


**[Projeto Rossmann:](https://github.com/jefferson-datascience/project_rossmann)** Nesse projeto, desenvolvi um modelo de previsão de vendas para a rede de Drogarias Rossmann que retorna o valor estimado das vendas das próximas 6 semanas das lojas da rede, sendo que o propósito final desse modelo é ajudar o CFO a montar o orçamento da reforma de cada uma dessas lojas tendo o conhecimento de quanto dinheiro terá em caixa. O retorno financeiro estimado para a rede com esse modelo ficou em torno de US$ 286.474.432,00 de faturamento com um margem de erro de US$ 1.000,00.
  <p>Para isso, utilizei o aprendizado de máquina sobre modelos preditivos, técnicas de análise exploratória e habilidade de extração e limpeza de dados. Além disso, para otimizar o processo de consulta a essas previsões construi um BOT no Telegram que, colocando apenas o número de identificação da loja é possível saber a previsão de vendas desses estabelecimentos. Logo, todas essas informações estão de fácil acesso bastando apenas ter um dispositivo móvel, internet e o Telegram instalado no dispositivo. Segue o link para acessar o BOT do Telegram:</p> 

<sub>**Ferramentas e Bibliotecas Utilizadas:** Python, Análise de Regessão, Modelos Preditivos(RandomForestRegressor, XGBoostRegressor), Aprendizagem de Máquina Supervisionado, Jupyter Notebook, Render.</sub>


**[Projeto Insurance All Cross-Sell:](https://github.com/jefferson-datascience/project_health_insurance_cross_sell)** Ajudei a equipe de vendas da Empresa Insurance All com a otimização do processo de prospecção de novos clientes para um novo produto que a empresa está oferecendo. A solução foi o desenvolvimento de um modelo de classificação rankeada que determina quais seriam os clientes com maior propensão de adquirir esse novo produto que a empresa estava introduzindo no seu portfólio de seguros. Com o modelo de classificação tendo um Recall at k de 99%, um Precision at k de 23% e uma equipe de vendas com uma capacidade de 20.000 ligações, estimou-se que 900 clientes interessados seriam atingidos gerando um faturamento de Rs(Rublos) 4.500.000
  <p>Além disso, para otimizar o processo de prospecção de novos clientes, criei um botão no AppScript da Planilha Sheets em que, uma vez passados os dados dos clientes corretamente para essa Planilha, basta um clique nesse botão para a planilha realizar uma requisição ao modelo via API para que ele retorne os clientes ranqueados na planilha e esteja pronto para a equipe de vendas usar. Segue o link da planilha com os dados e o botão de predição "Get Prediction":</p>
  
<sub>**Ferramentas e Bibliotecas Utilizadas:** Python, SQL, Análise de Regessão Logística, Modelos Classificação(RandomForestClassifier, XGBoostClassifier, Logistic Regressor, KNN Model, ExtraTreesClassifier), Aprendizagem de Máquina Supervisionado, Jupyter Notebook, Render.</sub>

**[Projeto All In One Place:](https://github.com/jefferson-datascience/project_clustering_customers)** Nesse projeto, ajudamos o time de negócios da empresa All In One Place(Outlet de Multimarcas) a determinar quem são os melhores clientes elegíveis para participar do programa Insiders(programa de mimos e benefícios para os melhores clientes), pois após um ano de funcionamento, a equipe de marketing percebeu que alguns de seus clientes de sua base compravam produtos mais caros e com uma certa alta frequência, e consequentemente, acabavam contribuindo com uma parcela significativa do faturamento da empresa.
  <p>A solução foi o desenvolvimento de um modelo de clusterização utilizando técnicas de espaços de embedding para determinar o grupo de melhores cliente. Por fim, com esse modelo, descobriu-se um grupo de melhores clientes que são responsáveis por 57% do faturamento da empresa, que é aproximadamente R$ 5.757.000,00.</p> 
  <p>Para estar monitorando esse grupo de melhores clientes(Clientes Insiders), os outros grupos de clientes e ter essas e outras informações de fácil acesso para montar estratégia de marketing e negócios, foi desenvolvido uma infraestrutura na AWS de ponta a ponta desde a ligação de uma EC2 passando pela criação de uma S3 até a elaboração Banco de Dados Postgres na RDS da Amazon para que os dados fossem consumidos em um Dashboard no MetaBase. Além disso, para que as informações se mantenham atualizadas, foi agendado a execução do modelo de clusterização a cada 15 dias de todo mês na EC2 pelo CronJob.</p>
  
 <sub>**Ferramentas e Bibliotecas Utilizadas:** Python, SQL, Análise de Agrupamentos, Modelos Clusterização(K-Means, Hierarchical Clustering, Gaussian Mixture Model), Técnicas de Embedding de Espaços, Aprendizagem de Máquina Não-Supervisionado, Jupyter Notebook, AWS, Linux, Metabase.</sub>
  

**[Projeto Eletronic House - Conversão de Compras:](https://github.com/jefferson-datascience/project_eletronic_house/tree/main/conversion_page)** Nesse projeto, o objetivo do Product Manager da e-commerce de eletrônicos Eletronic House era aumentar as vendas de Teclados Bluetooth. Assim, a equipe de desing desenvolveu uma nova página de vendas. Para determinar se valia a pena trocar a antiga página de vendas da empresa essa nova página sem ocorrer muitas perdas no faturamento foi desenvovlido um experimento estatístico utilizando técnicas de teste A/B. 
<p>A conclusão do teste foi que a nova página de vendas era melhor que a antiga com uma taxa de conversão de 0.8%, acarretando, um aumento estimado de R$ 3.600.000,00 no faturamento da empresa.</p> 

<sub>**Ferramentas e Bibliotecas Utilizadas:** Python, Scipy, StatsModels, Numpy</sub>


**[Projeto Eletronic House - Preenchimento Automático de Formulário:](https://github.com/jefferson-datascience/project_eletronic_house/tree/main/conversao_formulario_pagamento)** Dessa vez, na empresa Eletronic House, auxiliamos o Head de Designers a medir a efetividade de um novo dispositivo que realiza o preenchimento automático do formulário de pagamento. O objetivo final é determinar se o preenchimento automático interfere no aumento das compras. Para que esse problema fosse resolvido sem gerar grandes prejuízos para a empresa, nós utilizamos técnicas de teste A/B para trazer um solução.

<sub>**Ferramentas e Bibliotecas Utilizadas:** Python, Scipy, StatsModels, Numpy</sub>


**[Projeto Universidade de Montana:](https://github.com/jefferson-datascience/project_university_montana)** A Universidade de Montana possui vários serviços ao aluno, incluindo o serviço de biblioteca que oferece alocação de salas de estudos, livros, computadores e entre outros. Para facilitar esse processo, a Universidade colocou um botão com o nome "Interact" em sua página que encaminha o aluno para uma webpage para que ele solicite esses serviço por meio da Internet, assim, evitando a sobrecarga dos funcionários da Biblioteca. Entretanto, o time de TI percebeu, depois de um tempo, que a taxa de cliques do botão "Interact" estava baixa.
Portanto, com objetivo de aumentar a taxa de cliques desse botão, o time de TI sugeriu 4 possíveis novos títulos para o botão "Interact" que são "Connect", "Help", "Services", "Learn". Logo, para verificar a efetividade desses títulos e resolver o problema da taxa de cliques, nós utilizamos técnicas de teste A/B/n e Inferências Estatísticas para solucionar esse problema.

<sub>**Ferramentas e Bibliotecas Utilizadas:** Python, Scipy, StatsModels, Numpy</sub>


**[Projeto Análise de Banco de Dados Olist:](https://github.com/jefferson-datascience/project_sql_analysis)** Nesse projeto, fomos contratados como Cientista de Dados para investigar o Banco de Dados da Olist com o objetivo de realizar uma análise para responder a várias rodadas de questões de negócio dada pelo CEO.


## Ferramentas Utilizadas

**Linguagem de Programação:** Python, SQL, Webscraping com Python.

**FrameWork:** Flask, Streamlit.

**DataViz:** Tableau, MetaBase.

**Biblioteca de Visualização de Dados:** Seaborn, Matplotlib.

**Bibliotecas de Machine Learning:** Sklearn, Scipy, XGBoost.

**Bibliotecas de Extração de Dados:** Selenium, Beatiful Soup.

**Bibliotecas Estatísticas:** StatsModels, Scipy.

**Técnicas de Machine Learning:** Regressão Linear, Regressão Logística, Clusterização, Análise Preditiva, Agrupamentos.

**Estatística:** Teste A/B, Teste A/B/n

**Versionamento de Código:** Git, GitHub.

**Cloud Computing:** Heroku, Render, Streamlit, AWS.


![Statistics](https://github-readme-stats.vercel.app/api?username=jefferson-datascience&count_private=true)
